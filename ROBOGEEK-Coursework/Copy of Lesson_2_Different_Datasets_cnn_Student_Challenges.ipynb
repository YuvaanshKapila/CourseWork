{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tAhpEmN-4nD_PQxY41JeCnncv7ySH7c-","timestamp":1736121832047}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_yz-QM1sLt0C"},"source":["#Different Datasets (using Convolutional Neural Network)"]},{"cell_type":"markdown","metadata":{"id":"Q8lENOmkmiBF"},"source":["## AI-2020_Lab_02"]},{"cell_type":"markdown","metadata":{"id":"L-ACu_RnmiBG"},"source":["**Use Rock, Paper Scissors Lab 01 as a template for this exercise.**\n","\n","Consider whether the use of tfds-nightly datasets is necessary for your code, as it may provide additional functionality or data for your analysis.\n","\n","Remove the comment from the cell code to use this dataset if\n"," necessary.\n","\n","Switch from CPU to GPU in the Runtime settings when you need to accelerate your code, especially for computationally intensive tasks.\n","\n","Please make a new Notebook for each dataset and rename it with its name.\n","\n","Make the proper code changes to obtain the requirements for each dataset.\n","\n","Explore the following datasets:\n","\n","oxford_flowers102\n","\n","stanford_online_products\n","\n","cats_vs_dogs\n","\n","tf_flowers\n","\n","Determine and print the following dataset information:\n","\n","Author\n","Title\n","Year\n","Download Size\n","Homepage\n","Image shape\n","Number of TRAIN examples\n","Number of TEST examples\n","Number of VALIDATION examples\n","Number of label classes\n","Label Names\n","\n","Display the first twelve and the last six images of the train,  test, and validation data.\n","\n","If the number of classes is more than five, write the code to extract the top five classes of a number of elements.\n","\n","Create a new dataset with the top five classes for training, testing and validation. Name it accordingly and save them in your Google LOcal drive.\n","\n","It's crucial to update the Notebook with the proper names to keep your work organized and easily accessible."]},{"cell_type":"code","source":["!pip install -q tfds-nightly tensorflow matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lCzNIau08j3D","outputId":"910564c7-e29c-4c71-83c6-5a6701085ea8","executionInfo":{"status":"ok","timestamp":1736121991642,"user_tz":300,"elapsed":6643,"user":{"displayName":"Yuvaansh Kapila","userId":"02688970126196794756"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m184.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","import platform\n","\n","print('Python version:', platform.python_version())\n","print('Tensorflow version:', tf.__version__)\n","print('Keras version:', tf.keras.__version__)\n","\n","# See available datasets\n","tfds.list_builders()\n","\n","# Datasets to explore\n","DATASETS = [\n","    'oxford_flowers102',\n","    'stanford_online_products',\n","    'cats_vs_dogs',\n","    'tf_flowers'\n","]\n","\n","for DATASET_NAME in DATASETS:\n","    print(f\"\\nExploring dataset: {DATASET_NAME}\\n\")\n","\n","    # Load datasets with info\n","    (dataset_train_raw, dataset_test_raw), dataset_info = tfds.load(\n","        name=DATASET_NAME,\n","        with_info=True,\n","        as_supervised=True,\n","        split=[tfds.Split.TRAIN, tfds.Split.TEST],\n","    )\n","\n","    print('Raw train dataset size:', len(list(dataset_train_raw)))\n","    print('Raw test dataset size:', len(list(dataset_test_raw)))\n","\n","    # Dataset details\n","    NUM_TRAIN_EXAMPLES = dataset_info.splits['train'].num_examples\n","    NUM_TEST_EXAMPLES = dataset_info.splits['test'].num_examples\n","    NUM_CLASSES = dataset_info.features['label'].num_classes\n","\n","    print('Number of TRAIN examples:', NUM_TRAIN_EXAMPLES)\n","    print('Number of TEST examples:', NUM_TEST_EXAMPLES)\n","    print('Number of label classes:', NUM_CLASSES)\n","\n","    INPUT_IMG_SIZE_ORIGINAL = dataset_info.features['image'].shape[0]\n","    INPUT_IMG_SHAPE_ORIGINAL = dataset_info.features['image'].shape\n","\n","    INPUT_IMG_SIZE_REDUCED = INPUT_IMG_SIZE_ORIGINAL // 2\n","    INPUT_IMG_SHAPE_REDUCED = (\n","        INPUT_IMG_SIZE_REDUCED,\n","        INPUT_IMG_SIZE_REDUCED,\n","        INPUT_IMG_SHAPE_ORIGINAL[2]\n","    )\n","\n","    INPUT_IMG_SIZE = INPUT_IMG_SIZE_REDUCED\n","    INPUT_IMG_SHAPE = INPUT_IMG_SHAPE_REDUCED\n","\n","    print('Input image size (original):', INPUT_IMG_SIZE_ORIGINAL)\n","    print('Input image shape (original):', INPUT_IMG_SHAPE_ORIGINAL)\n","    print('Input image size (reduced):', INPUT_IMG_SIZE_REDUCED)\n","    print('Input image shape (reduced):', INPUT_IMG_SHAPE_REDUCED)\n","    print('Input image size:', INPUT_IMG_SIZE)\n","    print('Input image shape:', INPUT_IMG_SHAPE)\n","\n","    get_label_name = dataset_info.features['label'].int2str\n","\n","    print(get_label_name(0))\n","    print(get_label_name(1))\n","    if NUM_CLASSES > 2:\n","        print(get_label_name(2))\n","\n","    def preview_dataset(dataset):\n","        plt.figure(figsize=(12, 12))\n","        plot_index = 0\n","        for features in dataset.take(12):\n","            (image, label) = features\n","            plot_index += 1\n","            plt.subplot(3, 4, plot_index)\n","            label = get_label_name(label.numpy())\n","            plt.title('Label: %s' % label)\n","            plt.imshow(image.numpy())\n","\n","    preview_dataset(dataset_train_raw)\n","\n","    (first_image, first_label) = list(dataset_train_raw.take(1))[0]\n","    print('Label:', first_label.numpy())\n","    print('Image shape:', first_image.numpy().shape)\n","\n","    def format_example(image, label):\n","        image = tf.cast(image, tf.float32)\n","        image = image / 255.\n","        image = tf.image.resize(image, [INPUT_IMG_SIZE, INPUT_IMG_SIZE])\n","        return image, label\n","\n","    dataset_train = dataset_train_raw.map(format_example)\n","    dataset_test = dataset_test_raw.map(format_example)\n","\n","    (first_image, first_label) = list(dataset_train.take(1))[0]\n","    print('Label:', first_label.numpy())\n","    print('Image shape:', first_image.numpy().shape)\n","\n","    preview_dataset(dataset_train)\n"],"metadata":{"id":"mOb9NvUS7eF6","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"error","timestamp":1736206621557,"user_tz":300,"elapsed":27862,"user":{"displayName":"Yuvaansh Kapila","userId":"02688970126196794756"}},"outputId":"c64c16ab-98ad-4851-e713-90782c48ff54"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Python version: 3.10.12\n","Tensorflow version: 2.17.1\n","Keras version: 3.5.0\n","\n","Exploring dataset: oxford_flowers102\n","\n","Raw train dataset size: 1020\n","Raw test dataset size: 6149\n","Number of TRAIN examples: 1020\n","Number of TEST examples: 6149\n","Number of label classes: 102\n"]},{"output_type":"error","ename":"TypeError","evalue":"unsupported operand type(s) for //: 'NoneType' and 'int'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-abb3df278835>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mINPUT_IMG_SHAPE_ORIGINAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mINPUT_IMG_SIZE_REDUCED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUT_IMG_SIZE_ORIGINAL\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     INPUT_IMG_SHAPE_REDUCED = (\n\u001b[1;32m     49\u001b[0m         \u001b[0mINPUT_IMG_SIZE_REDUCED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'NoneType' and 'int'"]}]}]}